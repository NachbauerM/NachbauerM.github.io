# Book: The Signal and the Noise by Nate Silver

## General Information about Predictions
1.	We can never make perfectly objective predictions (always subjective). A Hypothesis should be falsifiable (Popper) and should be tested by means of prediction.
2.	Common forecasting mistakes: Events are out of sample (limited past experience, we know less about the world then assumed); High precision predictions with little accuracy.
3.	Often data is bad (garbage in garbage out)

## 2008 financial crisis:
1.	False assumption by rating agencies that risks were largely uncorrelated. E.g. “Bet wins unless all 5 mortgages (each 5% default rate) default”, If perfectly uncorrelated (independent) the probability of that happening is 0.00003%, if the defaults are perfectly correlated it is 5% (160.000x risk multiple).
2.	Risk: can put a price on. I know the odds of it happening and can account for it.
3.	Uncertainty: risk that is hard to quantify. 

## How to make better predictions
1.	Look for Consensus: Take an average (possible weighted for past accuracy) out of many predictions. Combine different kinds of data. Is better then the individual forecast but not always good. Works best if predictions are independent. Not necessarily better then the best forecasts. The further my prediction is from the average the more evidence I need.
2.	Think probabilistically: Articulate a range of possible outcomes (wide distribution of outcomes) with their probabilities. 
3.	Predictions should be updated: Update predictions with new information. “When the facts change, I change my mind” (Keynes).
4.	Don’t trust simple explanations/ models: Combine multiple data sources.
5.	Complex systems are hard to predict (e.g. weather): if they are dynamic (current behavior influences future) and nonlinear (exponential), both operations punish inaccuracies in data more.
6.	Avoid Overfitting: mistake noise for signal (noisy data) and underdeveloped theories. Giving an overly specific solution for a general problem. 
7.	Correlation without causation: Many indicators correlate coincidentally. Forecasts can create feedback loops (forecasts and based on that policies): Goodhart´s law! Make a good theory to back the data.
8.	Use Bayes Theorem (probability of an event if another has happened). Example:
Probability of my partner cheating on me if I find strange underwear at home. 
•	Prior Probability (best taken e.g from collective judgement): Initial estimate of how likely it is that the partner is cheating: x = 4%
•	Probability of underwear appearing conditional on the partner cheating (hypothesis is true): y = 50%
•	Probability of underwear appearing conditional on the partner not cheating (hypothesis is false): z= 5%.
•	Global Warming: There is a natural greenhouse effect that keeps the Earth warmer than it otherwise would be.
•	Posterior Probability, revised estimate of how likely it is that the partner is cheating given I have found underwear: (xy)/(xy + z(1-x)). The posterior probability becomes the new prior probability with new information.
9.	When trial and error works (e.g. AB testing): Run lots of experiments if possible. 
10.	Estimate Uncertainty: Uncertainty is an essential part of a forecast. E.g. reflected in the Prior probability. Admit to what we don’t know. Our perceptions of the world are approximations of the truth.
11.	Make a lot of forecast to get better.

## Judging a forecast
1.	Accuracy: how correct was the forecast?
2.	Consistency/ honesty: was it the best the forecaster was capable at the time? (Bias)
3.	Economic value: did the forecast help make better decisions?
4.	Better then persistence: Better then just assuming the event will be the same as today (e.g. weather) and better than the long term average.
5.	Test via calibration: How often did an event occur if I gave it a 40% probability of occurring? Requires a lot of data to evaluate, e.g. hundreds of predictions.
 
## Interesting
1.	Agent based modeling (computer simulations): simulate the behavior of every individual in an entire population. https://en.wikipedia.org/wiki/Agent-based_model.
2.	Scientific method: 1. Observe a phenomenon, 2. Develop a hypothesis, 3. Formulate a prediction form the hypothesis, 4. Test the prediction.
3.	Think in bets: bet on your predictions (probabilities). Prediction markets work well.
4.	Overconfidence bias: Most of us are overconfident when making a prediction.
